{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## divisé la data par 4\n",
        "Sirguey Franck"
      ],
      "metadata": {
        "id": "3DmTzqBEN8pY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries and Data Pre-processing:"
      ],
      "metadata": {
        "id": "gJLRWHrS3pbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7iyK8nN2Ru",
        "outputId": "402dc1d5-2b0e-47f6-8e18-42e36e14715a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Collecting neurite\n",
            "  Downloading neurite-0.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.23.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from neurite) (23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from neurite) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from neurite) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from neurite) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neurite) (1.2.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from neurite) (4.0.2)\n",
            "Collecting pystrum>=0.2 (from neurite)\n",
            "  Downloading pystrum-0.4.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurite) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->neurite) (67.7.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neurite) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neurite) (3.2.0)\n",
            "Building wheels for collected packages: pystrum\n",
            "  Building wheel for pystrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystrum: filename=pystrum-0.4-py3-none-any.whl size=19532 sha256=e4c4040026543afaafbab7f55d0010787449ca7ec56992f2210926c870d2b0a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/08/d0/914025beb5a12a855b8aafd22eeedc547198684a3f4409f66c\n",
            "Successfully built pystrum\n",
            "Installing collected packages: pystrum, neurite\n",
            "Successfully installed neurite-0.2 pystrum-0.4\n"
          ]
        }
      ],
      "source": [
        "# First, we install libraries needed\n",
        "!pip install tensorflow-probability neurite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow_probability as tfp\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import neurite as ne\n",
        "import time\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.losses import MeanSquaredError, SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "wMnzkWbnO1PY",
        "ExecuteTime": {
          "end_time": "2024-01-18T12:18:06.259360500Z",
          "start_time": "2024-01-18T12:18:06.183836600Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e03535-1653-4213-afdb-b39252efec54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O 20_2.zip 'https://www.dropbox.com/scl/fi/7i8vz4xf1butwswrlsiut/20_2.zip?rlkey=2zst37qihqcwxlo0uj2clq2yz&dl=1'\n",
        "with zipfile.ZipFile('20_2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('20_2')\n",
        "!wget -q -O 22_30.zip 'https://www.dropbox.com/scl/fi/y6w213bz7du8j573lafa9/22_30.zip?rlkey=1ark4xy6g1f3an055rdse4wms&dl=1'\n",
        "with zipfile.ZipFile('22_30.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('22_30')\n",
        "!wget -q -O 24_30.zip 'https://www.dropbox.com/scl/fi/otgqvneeo0mg2t7kslubc/24_30.zip?rlkey=2cyed13pwa16s1s1ucnun4y0y&dl=1'\n",
        "with zipfile.ZipFile('24_30.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('24_30')"
      ],
      "metadata": {
        "id": "R7aYX1H7k2E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the data (Based on a cut)\n",
        "images_route_24_30 = '24_30/24_30/'\n",
        "images_route_22_30 = '22_30/22_30/'\n",
        "images_route_20_2  = '20_2/20_2/'\n",
        "\n",
        "filelist_24_30 = sorted(glob.glob(f'{images_route_24_30}*.jpg'))\n",
        "filelist_22_30 = sorted(glob.glob(f'{images_route_22_30}*.jpg'))\n",
        "filelist_20_2 = sorted(glob.glob(f'{images_route_20_2}*.jpg'))\n",
        "\n",
        "# Rearranging because we forgot that lexicographic ordering exists lmao\n",
        "def custom_sort_key(filename):\n",
        "    filename_without_path = os.path.basename(filename)\n",
        "    numeric_part = int(filename_without_path.split(\".jpg\")[0])\n",
        "    return numeric_part\n",
        "\n",
        "filelist_24_30 = sorted(filelist_24_30, key=custom_sort_key)\n",
        "filelist_22_30 = sorted(filelist_22_30, key=custom_sort_key)\n",
        "filelist_20_2 = sorted(filelist_20_2, key=custom_sort_key)\n",
        "\n",
        "data_set_24_30 = np.array([np.array(Image.open(fname).convert('L')) for fname in filelist_24_30])\n",
        "data_set_22_30 = np.array([np.array(Image.open(fname).convert('L')) for fname in filelist_22_30])\n",
        "data_set_20_2 = np.array([np.array(Image.open(fname).convert('L')) for fname in filelist_20_2])\n",
        "\n",
        "# Print shapes\n",
        "print(f\"Shape of data 24_30 set: {data_set_24_30.shape}\")\n",
        "print(f\"Shape of data 22_30 set: {data_set_22_30.shape}\")\n",
        "print(f\"Shape of data 20_2 set: {data_set_20_2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clQ1iLtUPPAx",
        "outputId": "82b0702b-39c0-4c52-a46d-a50264d12e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data 24_30 set: (143, 960, 960)\n",
            "Shape of data 22_30 set: (168, 960, 960)\n",
            "Shape of data 20_2 set: (80, 960, 960)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from google.colab import files\n",
        "#bien changé la valeur de i en fonction de ce qu'on veut, ici par exemple on prends 960/2\n",
        "def divide_and_save_images(data_set, filelist, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for img_array, filename in zip(data_set, filelist):\n",
        "        # Original image name without extension\n",
        "        base_filename = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "        # Divide the image into four parts\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                sub_img = img_array[i*480:(i+1)*480, j*480:(j+1)*480]\n",
        "                sub_img_pil = Image.fromarray(sub_img)\n",
        "\n",
        "                # New filename for each sub-image\n",
        "                new_filename = f\"{output_folder}/{base_filename}{i+1}{j+1}.jpg\"\n",
        "                sub_img_pil.save(new_filename)\n",
        "\n",
        "# Example usage\n",
        "divide_and_save_images(data_set_24_30, filelist_24_30, 'output_24_30')\n",
        "divide_and_save_images(data_set_22_30, filelist_22_30, 'output_22_30')\n",
        "divide_and_save_images(data_set_20_2, filelist_20_2, 'output_20_2')\n",
        "#je les telecharges pour envoyé\n",
        "for folder in ['output_24_30', 'output_22_30', 'output_20_2']:\n",
        "    shutil.make_archive(folder, 'zip', folder)\n",
        "    files.download(f\"{folder}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LaCvInItTecJ",
        "outputId": "74c1467d-20cb-4446-b622-ed6da5733d9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6566b770-0b87-424b-ae06-fa984cf9ec1a\", \"output_24_30.zip\", 15899082)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5f6971aa-e661-4e81-b584-b3e9dd5df49b\", \"output_22_30.zip\", 29682031)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e58c148-9b52-4767-bdf3-0f70b84a2555\", \"output_20_2.zip\", 4463590)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}